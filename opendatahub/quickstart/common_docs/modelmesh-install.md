# Installing OpenDataHub ModelServing

## Prerequisites

- You have `git` installed.

## Procedure

1. Get the latest OpenDataHub ModelServing release:

```
git clone https://github.com/opendatahub-io/modelmesh-serving.git

cd modelmesh-serving
```

2. Run the install script:

```
cd opendatahub/quickstart/$QUICK_START_FOLDER # (for example, cd opendatahub/quickstart/basic)

source ../env.sh

./deploy.sh
```

This script installs OpenDataHub ModelServing Controller in the `opendatahub` namespace and NFS Provisioner in the `nfs-provisioner` namespace. It installs the test components, such as Minio and PVC, in the `modelmesh-serving` namespace.

**Note**: The NFS Provisioner and MinIO deployments are intended for development/experimentation purposes and not for production. Also, `deploy.sh` installs ModelServing without the OpenDataHub operator. For a production environment, you should deploy ModelServing with the OpenDataHub operator as described in [the OpenDataHub Quick Installation guide](http://opendatahub.io/docs/getting-started/quick-installation.html).

## Verify installation

After running the `deploy.sh` script, you should see a `Successfully deployed ModelMesh Serving/ODH Model Controller/NFS Provisioner/Sample Model!` message.

1. View the OpenDataHub pods:

```
$ oc get pod -n opendatahub
```

You should see a result similar to the following:

```
NAME                                    READY   STATUS    RESTARTS   AGE
etcd-6c4699b675-nvl62                   1/1     Running   0          94s
modelmesh-controller-59b4546559-2tcgb   1/1     Running   0          94s
modelmesh-controller-59b4546559-m82px   1/1     Running   0          94s
modelmesh-controller-59b4546559-tzkjl   1/1     Running   0          94s
odh-model-controller-7c87fd685-2nhpk    1/1     Running   0          94s
odh-model-controller-7c87fd685-zkm25    1/1     Running   0          94s
odh-model-controller-7c87fd685-zxlss    1/1     Running   0          94s
```

2. View NFS-Provisioner pods:

```
$ oc get pod -n nfs-provisioner
```

You should see a result similar to the following:

```
NAME                              READY   STATUS    RESTARTS   AGE
nfs-provisioner-f7c7b56bc-c425b   1/1     Running   0          60s
```

3. View ModelMesh Runtime pods:

```
$ oc get pod -n modelmesh-serving
```

You should see a result similar to the following:

```
NAME                                          READY   STATUS      RESTARTS   AGE
minio-5f6cf8dd56-5v96n                        1/1     Running     0          76s
modelmesh-serving-ovms-1.x-6d84c548bb-68xp5   5/5     Running     0          44s
modelmesh-serving-ovms-1.x-6d84c548bb-j6fdz   5/5     Running     0          44s
pvc-init-zrqqv                                0/1     Completed   0          76s
pvc-reader                                    1/1     Running     0          76s
```

4. Check available ServingRuntimes:

```
$ oc get servingruntimes -n modelmesh-serving
```

You should see a result similar to the following:

```
NAME       DISABLED   MODELTYPE     CONTAINERS   AGE
ovms-1.x              openvino_ir   ovms         78s
```

Optionally, you can create custom runtimes such as mlserver or triton.

The current mappings of ServingRuntime and Frameworks is as follows:

| ServingRuntime | Supported Frameworks                |
| -------------- | ----------------------------------- |
| mlserver-0.x   | sklearn, xgboost, lightgbm          |
| ovms-1.x       | openvino_ir, onnx                   |
| torchserve-0.x | pytorch-mar                         |
| triton-2.x     | tensorflow, pytorch, onnx, tensorrt |

5. Optionally, for testing purposes, create the runtimes with the following command:

```
kustomize build ${OPENDATAHUB_DIR}/scripts/manifests/runtimes | oc create -f -
```

View other model server runtimes.

```
$ oc get servingruntimes -n modelmesh-serving
NAME             DISABLED   MODELTYPE     CONTAINERS   AGE
mlserver-0.x                sklearn       mlserver     6s
ovms-1.x                    openvino_ir   ovms         17m
torchserve-0.x              pytorch-mar   torchserve   6s
triton-2.x                  keras         triton       6s
```
